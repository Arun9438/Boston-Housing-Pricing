{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9OJ+BpJWxmaffLWH6XEf/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arun9438/Boston-Housing-Pricing/blob/main/Useful_NLP_Libraries_%26_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1: Compare and contrast NLTK and spaCy in terms of features, ease of use, and performance.\n",
        "\n",
        "NLTK and spaCy are two popular Python libraries for Natural Language Processing, but they are designed for different purposes.\n",
        "\n",
        "| Aspect            | NLTK                  | spaCy                         |\n",
        "| ----------------- | --------------------- | ----------------------------- |\n",
        "| Primary Focus     | Education & research  | Industrial & production use   |\n",
        "| Ease of Use       | Requires more coding  | Simple and user-friendly      |\n",
        "| Speed             | Slower                | Very fast                     |\n",
        "| Pretrained Models | Limited               | Advanced pretrained pipelines |\n",
        "| Use Case          | Learning NLP concepts | Real-world applications       |\n",
        "\n",
        "NLTK is ideal for beginners and academic learning, whereas spaCy is preferred for high-performance NLP applications in industry."
      ],
      "metadata": {
        "id": "O8ocaDirpy6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2: What is TextBlob and how does it simplify common NLP tasks like sentiment analysis and translation?\n",
        "\n",
        "TextBlob is a high-level Python library built on top of NLTK and Pattern that simplifies common NLP tasks. It provides an easy-to-use API for sentiment analysis, part-of-speech tagging, noun phrase extraction, translation, and language detection.\n",
        "For example, sentiment analysis can be performed in a single line of code, returning polarity and subjectivity scores without manually building models. This simplicity makes TextBlob ideal for quick prototyping and small-scale NLP tasks."
      ],
      "metadata": {
        "id": "XUofASrap4FD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3: Explain the role of Stanford NLP in academic and industry NLP projects.\n",
        "Stanford NLP provides state-of-the-art NLP tools developed by Stanford University. It is widely used in both academia and industry due to its accuracy and linguistic depth.\n",
        "In academia, Stanford NLP is used for research in syntactic parsing, named entity recognition, and semantic analysis. In industry, it supports applications such as information extraction, chatbots, and document classification. Its CoreNLP toolkit supports multiple languages and deep linguistic annotations."
      ],
      "metadata": {
        "id": "_53t6JJeqIaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4: Describe the architecture and functioning of a Recurrent Neural Network (RNN).\n",
        "\n",
        "A Recurrent Neural Network (RNN) is a neural network designed to process sequential data such as text or time series. Unlike feedforward networks, RNNs have loops that allow information to persist across time steps.\n",
        "At each time step, the network takes the current input and the previous hidden state to produce a new hidden state. This enables RNNs to capture contextual information in sequences, making them suitable for NLP tasks like language modeling and text generation.\n",
        "However, standard RNNs suffer from vanishing gradient problems when handling long sequences."
      ],
      "metadata": {
        "id": "WjYwF5rkqP8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5: What is the key difference between LSTM and GRU networks in NLP applications?\n",
        "\n",
        "LSTM (Long Short-Term Memory) and GRU (Gated Recurrent Unit) are advanced RNN architectures designed to overcome vanishing gradient problems.\n",
        "LSTM uses three gates (input, forget, output) and a memory cell, making it powerful but computationally heavy.\n",
        "GRU uses two gates (reset and update), making it simpler and faster.\n",
        "Both perform well in NLP tasks, but GRUs are preferred when computational efficiency is important."
      ],
      "metadata": {
        "id": "fFKtLfDgqWi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6: Sentiment analysis using TextBlob"
      ],
      "metadata": {
        "id": "p6WAmNKYqcK0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLymacE6piXL",
        "outputId": "ae10d7d9-c275-44df-df87-2d53f61912a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polarity: 0.21742424242424244\n",
            "Subjectivity: 0.6511363636363636\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text = \"\"\"I had a great experience using the new mobile banking app.\n",
        "The interface is intuitive, and customer support was quick to resolve my issue.\n",
        "However, the app did crash once during a transaction, which was frustrating\"\"\"\n",
        "\n",
        "blob = TextBlob(text)\n",
        "\n",
        "print(\"Polarity:\", blob.sentiment.polarity)\n",
        "print(\"Subjectivity:\", blob.sentiment.subjectivity)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 7: Tokenization and Frequency Distribution using NLTK"
      ],
      "metadata": {
        "id": "MSjwFjY7qjWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Added to resolve the LookupError\n",
        "\n",
        "text = \"\"\"Natural Language Processing (NLP) is a fascinating field that combines\n",
        "linguistics, computer science, and artificial intelligence.\"\"\"\n",
        "\n",
        "tokens = word_tokenize(text.lower())\n",
        "freq_dist = FreqDist(tokens)\n",
        "\n",
        "print(freq_dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1i4VjA7qe1i",
        "outputId": "f17cb5da-68db-4faf-86f1-ac65e37513ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FreqDist with 20 samples and 21 outcomes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 8: Basic LSTM model using Keras"
      ],
      "metadata": {
        "id": "q2bRymGVqv2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "texts = [\n",
        "    \"I love this project\",\n",
        "    \"This is an amazing experience\",\n",
        "    \"I hate waiting in line\",\n",
        "    \"This is the worst service\",\n",
        "    \"Absolutely fantastic\"\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0, 0, 1]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded = pad_sequences(sequences)\n",
        "\n",
        "labels = np.array(labels) # Convert labels to a NumPy array\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=100, output_dim=16))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(padded, labels, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZiAvtZIql-J",
        "outputId": "07cf6b58-f9b9-48cd-95ce-a1c889c19c1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2000 - loss: 0.6949\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4000 - loss: 0.6930\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6000 - loss: 0.6910\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6000 - loss: 0.6891\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6000 - loss: 0.6871\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6000 - loss: 0.6851\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6000 - loss: 0.6830\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6000 - loss: 0.6809\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6000 - loss: 0.6787\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6000 - loss: 0.6763\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78d826596750>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 9: spaCy NLP pipeline"
      ],
      "metadata": {
        "id": "wN3hSq0vq17f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"\"\"Homi Jehangir Bhaba was an Indian nuclear physicist who played a key role\n",
        "in the development of India’s atomic energy program.\"\"\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_)\n",
        "\n",
        "print(\"Entities:\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpxqLjgpqyeJ",
        "outputId": "cd4124bc-9a82-44be-fcc0-a6b387a9ed46"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Homi Homi\n",
            "Jehangir Jehangir\n",
            "Bhaba Bhaba\n",
            "was be\n",
            "an an\n",
            "Indian indian\n",
            "nuclear nuclear\n",
            "physicist physicist\n",
            "who who\n",
            "played play\n",
            "a a\n",
            "key key\n",
            "role role\n",
            "\n",
            " \n",
            "\n",
            "in in\n",
            "the the\n",
            "development development\n",
            "of of\n",
            "India India\n",
            "’s ’s\n",
            "atomic atomic\n",
            "energy energy\n",
            "program program\n",
            ". .\n",
            "Entities:\n",
            "Homi Jehangir Bhaba FAC\n",
            "Indian NORP\n",
            "India GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 10: Chatbot for mental health platform\n",
        "\n",
        "Architecture:\n",
        "Input layer → Embedding layer → LSTM/GRU → Dense layer\n",
        "spaCy or Stanford NLP for entity recognition and intent detection\n",
        "Data Preprocessing:\n",
        "Text cleaning and normalization\n",
        "Tokenization and lemmatization\n",
        "Padding sequences for uniform input\n",
        "Ethical Considerations:\n",
        "User privacy and data security\n",
        "Avoiding harmful or biased responses\n",
        "Clear disclaimers (not a replacement for professional help)"
      ],
      "metadata": {
        "id": "xefmpNPZrBHa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Naggfjtq4Q-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}